#  Deep MNIST for Experts <a class="md-anchor" id="AUTOGENERATED-deep-mnist-for-experts"></a>

TensorFlow是一个强力大规模数值计算的库。其中一个特点就是它能够实现和训练深度神经网络。
在这一小节里，我们将会学习在MNIST上构建深度卷积分类器的基本步骤。

*这个教程假设你已经熟悉神经网络和MNIST数据集。如果你尚未了结，请查看[新手指南](../../../tutorials/mnist/beginners/index.md).*

## 安装 <a class="md-anchor" id="AUTOGENERATED-setup"></a>

在我们创建model之前，我们会先加载MNIST数据集，然后启动一个TensorFlow的session。

### 加载MNIST数据 <a class="md-anchor" id="AUTOGENERATED-load-mnist-data"></a>

为了方便起见，我们已经准备了[一个脚本](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/input_data.py)来自动下载和导入MNIST数据集。它会自动创建一个`'MNIST_data'`的目录来存储数据。

```python
import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
```

这里，`mnist`是一个轻量级的类。它包含训练、校验和测试用NumPy装在的集合数据。同时对数据进行最小划分的方式来提供迭代器，后面我们将会用到。

### 开始TensorFlow的交互会话 <a class="md-anchor" id="AUTOGENERATED-start-tensorflow-interactivesession"></a>

Tensorflow是基于一个高效的C++模块进行运算。而与这个模块的连接叫做session。一般而言，使用TensorFlow程序的流程是先创建一个图，然后在sission中加载它。

这里，我们使用更加方便的`InteractiveSession`类。通过它，你可以更加灵活地构建你的代码。它能让你在运行图的时候，插入一些构建[计算图](../../../get_started/basic_usage.md#the-computation-graph)的操作。如果你没有使用`InteractiveSession`的话，你需要在开始session和[加载图](../../../get_started/basic_usage.md#launching-the-graph-in-a-session)之前，构建整个计算图。


```python
import tensorflow as tf
sess = tf.InteractiveSession()
```

#### 计算图 <a class="md-anchor" id="AUTOGENERATED-computation-graph"></a>

传统的计算行为，为了更高效地在Python里进行数值计算，我们一般会使用像NumPy一类其他语言编写的lib，来完成这些费时的操作（例如矩阵运算）。可是，每一步操作依然会有大量在Python和第三方lib之间的切换操作。这些操作很蛋疼，特别是你想在GPU上进行计算，又或者想使用分布式的做法的时候。因为它会让你在数据传输上耗费大量功夫。

而在TensorFlow中，也有Python与外界的频繁操作。但是它在这一方面，做了进一步的改良。除了能够
在Python以外单独执行费时操作之外，TensorFlow还能通过描述计算图来调度Python外的计算。这与Theano、Torch的用法很相似。

所以，这部分Python代码，扮演的是协调整个运算过程，调度和安排每一步的运行。详细请阅读[计算图](../../../get_started/basic_usage.md#the-computation-graph)
部分的
[基本用法](../../../get_started/basic_usage.md)
for more detail.


## 构建Softmax Regression模型 <a class="md-anchor" id="AUTOGENERATED-build-a-softmax-regression-model"></a>

在这小节里，我们将会构建一个一层线性的softmax regression模型。下一节里，我们会扩展到多层卷积网络。

### 占位符 <a class="md-anchor" id="AUTOGENERATED-placeholders"></a>

我们先来创建计算图的输入和输出。

We start building the computation graph by creating nodes for the
input images and target output classes.

```python
x = tf.placeholder("float", shape=[None, 784])
y_ = tf.placeholder("float", shape=[None, 10])
```

这里的`x`和`y`并不是具体值，他们是一个`placeholder`，他们是一个变量，在TensorFlow运行计算的时候使用。

输入值图片集`x`包括一堆的2维矢量。这里，我给它定义它的`shape`为`[None, 784]`，其中`784`代表一个展开的MNIST图片的维度数。而`None`代表第1维是单个批次的数量，为任意值。输出值`y_`也是一个2维矢量，其中每一行为一个10维向量代表对应MNIST图片的分类。

虽然`placeholder`的`shape`参数是可选的，但有了它，TensorFlow能够自动捕捉那些不一致的数据。

### Variables <a class="md-anchor" id="AUTOGENERATED-variables"></a>

我们现在为模型定义权重`W`和偏差`b`。

We now define the weights `W` and biases `b` for our model. We could imagine treating
these like additional inputs, but TensorFlow has an even better way to handle
them: `Variable`.
A `Variable` is a value that lives in TensorFlow's computation graph.
It can be used and even modified by the computation. In machine
learning applications, one generally has the model paramaters be `Variable`s.

```python
W = tf.Variable(tf.zeros([784,10]))
b = tf.Variable(tf.zeros([10]))
```

We pass the initial value for each parameter in the call to `tf.Variable`.
In this case, we initialize both `W` and `b` as tensors full of
zeros. `W` is a 784x10 matrix (because we have 784 input features
and 10 outputs) and `b` is a 10-dimensional vector (because we have 10 classes).

Before `Variable`s can be used within a session, they must be initialized using
that session.
This step takes the initial values (in this case tensors full of zeros) that
have already been specified, and assigns them to each `Variable`. This can be
done for all `Variables` at once.

```python
sess.run(tf.initialize_all_variables())
```

### Predicted Class and Cost Function <a class="md-anchor" id="AUTOGENERATED-predicted-class-and-cost-function"></a>

We can now implement our regression model. It only takes one line!
We multiply the vectorized input images `x` by the weight matrix `W`, add
the bias `b`, and compute the softmax probabilities that are assigned to each
class.

```python
y = tf.nn.softmax(tf.matmul(x,W) + b)
```

The cost function to be minimized during training can be specified just as
easily. Our cost function will be the cross-entropy between the target and the
model's prediction.

```python
cross_entropy = -tf.reduce_sum(y_*tf.log(y))
```

Note that `tf.reduce_sum` sums across all images in the minibatch, as well as
all classes. We are computing the cross entropy for the entire minibatch.

## Train the Model <a class="md-anchor" id="AUTOGENERATED-train-the-model"></a>

Now that we have defined our model and training cost function, it is
straightforward to train using TensorFlow.
Because TensorFlow knows the entire computation graph, it
can use automatic differentiation to find the gradients of the cost with
respect to each of the variables.
TensorFlow has a variety of
[builtin optimization algorithms]
(../../../api_docs/python/train.md#optimizers).
For this example, we will use steepest gradient descent, with a step length of
0.01, to descend the cross entropy.

```python
train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)
```

What TensorFlow actually did in that single line was to add new operations to
the computation graph. These operations included ones to compute gradients,
compute parameter update steps, and apply update steps to the parameters.

The returned operation `train_step`, when run, will apply the gradient
descent updates to the parameters. Training the model can therefore be
accomplished by repeatedly running `train_step`.

```python
for i in range(1000):
  batch = mnist.train.next_batch(50)
  train_step.run(feed_dict={x: batch[0], y_: batch[1]})
```

Each training iteration we load 50 training examples. We then run the
`train_step` operation, using `feed_dict` to replace the `placeholder` tensors
`x` and `y_` with the training examples.
Note that you can replace any tensor in your computation graph using `feed_dict`
-- it's not restricted to just `placeholder`s.

### Evaluate the Model <a class="md-anchor" id="AUTOGENERATED-evaluate-the-model"></a>

How well did our model do?

First we'll figure out where we predicted the correct label. `tf.argmax`
is an extremely useful function which gives you the index of the highest entry
in a tensor along some axis. For example, `tf.argmax(y,1)` is the label our
model thinks is most likely for each input, while `tf.argmax(y_,1)` is the
true label. We can use `tf.equal` to check if our prediction matches the
truth.

```python
correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
```

That gives us a list of booleans. To determine what fraction are correct, we
cast to floating point numbers and then take the mean. For example,
`[True, False, True, True]` would become `[1,0,1,1]` which would become `0.75`.

```python
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
```

Finally, we can evaluate our accuracy on the test data. This should be about
91% correct.

```python
print accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})
```

## Build a Multilayer Convolutional Network <a class="md-anchor" id="AUTOGENERATED-build-a-multilayer-convolutional-network"></a>

Getting 91% accuracy on MNIST is bad. It's almost embarrassingly bad. In this
section, we'll fix that, jumping from a very simple model to something moderatly
sophisticated: a small convolutional neural network. This will get us to around
99.2% accuracy -- not state of the art, but respectable.

### Weight Initialization <a class="md-anchor" id="AUTOGENERATED-weight-initialization"></a>

To create this model, we're going to need to create a lot of weights and biases.
One should generally initialize weights with a small amount of noise for
symmetry breaking, and to prevent 0 gradients. Since we're using ReLU neurons,
it is also good practice to initialize them with a slightly positive initial
bias to avoid "dead neurons." Instead of doing this repeatedly while we build
the model, let's create two handy functions to do it for us.

```python
def weight_variable(shape):
  initial = tf.truncated_normal(shape, stddev=0.1)
  return tf.Variable(initial)

def bias_variable(shape):
  initial = tf.constant(0.1, shape=shape)
  return tf.Variable(initial)
```

### Convolution and Pooling <a class="md-anchor" id="AUTOGENERATED-convolution-and-pooling"></a>

TensorFlow also gives us a lot of flexibility in convolution and pooling
operations. How do we handle the boundaries? What is our stride size?
In this example, we're always going to choose the vanilla version.
Our convolutions uses a stride of one and are zero padded so that the
output is the same size as the input. Our pooling is plain old max pooling
over 2x2 blocks. To keep our code cleaner, let's also abstract those operations
into functions.

```python
def conv2d(x, W):
  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')

def max_pool_2x2(x):
  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1], padding='SAME')
```

### First Convolutional Layer <a class="md-anchor" id="AUTOGENERATED-first-convolutional-layer"></a>

We can now implement our first layer. It will consist of convolution, followed
by max pooling. The convolutional will compute 32 features for each 5x5 patch.
Its weight tensor will have a shape of `[5, 5, 1, 32]`. The first two
dimensions are the patch size, the next is the number of input channels, and
the last is the number of output channels. We will also have a bias vector with
a component for each output channel.

```python
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
```

To apply the layer, we first reshape `x` to a 4d tensor, with the second and
third dimensions corresponding to image width and height, and the final
dimension corresponding to the number of color channels.

```python
x_image = tf.reshape(x, [-1,28,28,1])
```

We then convolve `x_image` with the weight tensor, add the
bias, apply the ReLU function, and finally max pool.

```python
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)
```

### Second Convolutional Layer <a class="md-anchor" id="AUTOGENERATED-second-convolutional-layer"></a>

In order to build a deep network, we stack several layers of this type. The
second layer will have 64 features for each 5x5 patch.

```python
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])

h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
```

### Densely Connected Layer <a class="md-anchor" id="AUTOGENERATED-densely-connected-layer"></a>

Now that the image size has been reduced to 7x7, we add a fully-connected layer
with 1024 neurons to allow processing on the entire image. We reshape the tensor
from the pooling layer into a batch of vectors,
multiply by a weight matrix, add a bias, and apply a ReLU.

```python
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])

h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
```

#### Dropout <a class="md-anchor" id="AUTOGENERATED-dropout"></a>

To reduce overfitting, we will apply dropout before the readout layer.
We create a `placeholder` for the probability that a neuron's output is kept
during dropout. This allows us to turn dropout on during training, and turn it
off during testing.
TensorFlow's `tf.nn.dropout` op automatically handles scaling neuron outputs in
addition to masking them, so dropout just works without any additional scaling.

```python
keep_prob = tf.placeholder("float")
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
```

### Readout Layer <a class="md-anchor" id="AUTOGENERATED-readout-layer"></a>

Finally, we add a softmax layer, just like for the one layer softmax regression
above.

```python
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])

y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)
```

### Train and Evaluate the Model <a class="md-anchor" id="AUTOGENERATED-train-and-evaluate-the-model"></a>

How well does this model do?
To train and evaluate it we will use code that is nearly identical to that for
the simple one layer SoftMax network above.
The differences are that: we will replace the steepest gradient descent
optimizer with the more sophisticated ADAM optimizer; we will include the
additional parameter `keep_prob` in `feed_dict` to control the dropout rate;
and we will add logging to every 100th iteration in the training process.

```python
cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
sess.run(tf.initialize_all_variables())
for i in range(20000):
  batch = mnist.train.next_batch(50)
  if i%100 == 0:
    train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})
    print "step %d, training accuracy %g"%(i, train_accuracy)
  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})

print "test accuracy %g"%accuracy.eval(feed_dict={
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})
```

The final test set accuracy after running this code should be approximately 99.2%.

We have learned how to quickly and easily build, train, and evaluate a
fairly sophisticated deep learning model using TensorFlow.
