# 数据读取 <a class="md-anchor" id="AUTOGENERATED-reading-data"></a>

TensorFlow程序读取数据一共有3种方法:

*   供给数据(Feeding)： 在TensorFlow程序运行的每一步， 让Python代码来供给数据。
*   从文件读取数据： 在TensorFlow图的起始， 让一个输入管线从文件中读取数据。
*   预加载数据： 在TensorFlow图中定义常量或变量来保存所有数据(仅适用于数据量比较小的情况)。

<!-- TOC-BEGIN This section is generated by neural network: DO NOT EDIT! -->
## 目录
### [数据读取](#AUTOGENERATED-reading-data)
* [供给数据(Feeding)](#Feeding)
* [从文件读取数据](#AUTOGENERATED-reading-from-files)
  * [文件名, 乱序(shuffling), 和最大训练迭代数(epoch limits)](#AUTOGENERATED-filenames--shuffling--and-epoch-limits)
  * [文件格式](#AUTOGENERATED-file-formats)
  * [预处理](#AUTOGENERATED-preprocessing)
  * [批处理](#AUTOGENERATED-batching)
  * [使用`QueueRunner`创建预读线程](#QueueRunner)
  * [对记录进行过滤或者为每个纪录创建多个样本](#AUTOGENERATED-filtering-records-or-producing-multiple-examples-per-record)
  * [序列化输入数据(Sparse input data)](#AUTOGENERATED-sparse-input-data)
* [预加载数据](#AUTOGENERATED-preloaded-data)
* [多管线输入](#AUTOGENERATED-multiple-input-pipelines)


<!-- TOC-END This section was generated by neural network, THANKS FOR READING! -->

## 供给数据 <a class="md-anchor" id="Feeding"></a>

TensorFlow的数据供给机制允许你在TensorFlow运算图中将数据注入到任一张量中。因此，python运算可以把数据直接设置到TensorFlow图中。

通过给run()或者eval()函数输入`feed_dict`参数， 可以启动运算过程。

```python
with tf.Session():
  input = tf.placeholder(tf.float32)
  classifier = ...
  print classifier.eval(feed_dict={input: my_python_preprocessing_fn()})
```

虽然你可以使用常量和变量来替换任何一个张量， 但是最好的做法应该是使用[`placeholder` op](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#placeholder)节点。设计`placeholder`节点的唯一的意图就是为了提供数据供给(feeding)的方法。`placeholder`节点被声明的时候是未初始化的， 也不包含数据， 如果没有为它供给数据， 则TensorFlow运算的时候会产生错误， 所以千万不要忘了为`placeholder`提供数据。

可以在[`tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py)找到使用`placeholder`和MNIST训练的例子，[MNIST tutorial](tensorflow-zh/SOURCE/tutorials/mnist/tf/index.md)也讲述了这一例子。

## 从文件读取数据 <a class="md-anchor" id="AUTOGENERATED-reading-from-files"></a>

一共典型的文件读取管线会包含下面这些步骤：

1.  文件名列表
2.  *可配置的* 文件名乱序(shuffling)
3.  *可配置的* 最大训练迭代数(epoch limit)
4.  文件名队列
5.  针对输入文件格式的阅读器
6.  纪录解析器
7.  *可配置的*预处理器
8.  样本队列

### 文件名, 乱序(shuffling), 和最大训练迭代数(epoch limits) <a class="md-anchor" id="AUTOGENERATED-filenames--shuffling--and-epoch-limits"></a>

可以使用字符串张量(比如`["file0", "file1"]`, `[("file%d" % i) for i in range(2)]`， `[("file%d" % i) for i in range(2)]`) 或者[`tf.train.match_filenames_once` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#match_filenames_once)来产生文件名列表。

将文件名列表交给[`tf.train.string_input_producer` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#string_input_producer).`string_input_producer`来生成一个先入先出的队列， 文件阅读器会需要它来读取数据。

`string_input_producer` 提供的可配置参数来设置文件名乱序和最大的训练迭代数， `QueueRunner`会为每次迭代(epoch)将所有的文件名加入文件名队列中， 如果`shuffle=True`的话， 会对文件名进行乱序处理。这一过程是比较均匀的，因此它可以产生均衡的文件名队列。

这个`QueueRunner`的工作线程是独立于文件阅读器的线程， 因此乱序和将文件名推入到文件名队列这些过程不会阻塞文件阅读器运行。

### 文件格式 <a class="md-anchor" id="AUTOGENERATED-file-formats"></a>

根据你的文件格式， 选择对应的文件阅读器， 然后将文件名队列提供给阅读器的`read`方法。阅读器的`read`方法会输出一个key来表征输入的文件和其中的纪录(对于调试非常有用)，同时得到一个字符串标量， 这个字符串标量可以被一个或多个解析器，或者转换操作将其解码为张量并且构造称为样本。

#### CSV 文件 <a class="md-anchor" id="AUTOGENERATED-csv-files"></a>

从CSV文件中读取数据， 需要使用[`TextLineReader`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#TextLineReader)和[`decode_csv`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#decode_csv) 操作， 如下面的例子所示：

```python
filename_queue = tf.train.string_input_producer(["file0.csv", "file1.csv"])

reader = tf.TextLineReader()
key, value = reader.read(filename_queue)

# Default values, in case of empty columns. Also specifies the type of the
# decoded result.
record_defaults = [[1], [1], [1], [1], [1]]
col1, col2, col3, col4, col5 = tf.decode_csv(
    value, record_defaults=record_defaults)
features = tf.concat(0, [col1, col2, col3, col4])

with tf.Session() as sess:
  # Start populating the filename queue.
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)

  for i in range(1200):
    # Retrieve a single instance:
    example, label = sess.run([features, col5])

  coord.request_stop()
  coord.join(threads)
```
每次`read`的执行都会从文件中读取一行内容， `decode_csv` 操作会解析这一行内容并将其转为张量列表。如果输入的参数有缺失，`record_default`参数可以根据张量的类型来设置默认值。

在调用`run`或者`eval`去执行`read`之前， 你必须调用`tf.train.start_queue_runners`来将文件名填充到队列。否则`read`操作会被阻塞到文件名队列中有值为止。

#### 固定长度的记录 <a class="md-anchor" id="AUTOGENERATED-fixed-length-records"></a>

从二进制文件中读取固定长度纪录， 可以使用[`tf.FixedLengthRecordReader`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#FixedLengthRecordReader)的[`tf.decode_raw`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#decode_raw)操作。`decode_raw`操作可以讲一个字符串转换为一个uint8的张量。

举例来说，[the CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.html)的文件格式定义是：每条记录的长度都是固定的，一个字节的标签，后面是3072字节的图像数据。uint8的张量的标准操作就可以从中获取图像片并且根据需要进行重组。 例子代码可以在[`tensorflow/models/image/cifar10/cifar10_input.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/cifar10_input.py)找到，具体讲述可参见[教程](tensorflow-zh/SOURCE/tutorials/deep_cnn/index.md#prepare-the-data).

#### 标准TensorFlow格式 <a class="md-anchor" id="AUTOGENERATED-standard-tensorflow-format"></a>

另一种保存记录的方法可以允许你讲任意的数据转换为TensorFlow所支持的格式， 这种方法可以使TensorFlow的数据集更容易与网络应用架构相匹配。这种建议的方法就是使用TFRecords文件，TFRecords文件包含了[`tf.train.Example` 协议内存块(protocol buffer)](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/example.proto)(协议内存块包含了字段
[`Features`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/feature.proto))。你可以写一段代码获取你的数据， 将数据填入到`Example`协议内存块(protocol buffer)，将协议内存块序列化为一个字符串， 并且通过[`tf.python_io.TFRecordWriter` class](tensorflow-zh/SOURCE/api_docs/python/python_io.md#TFRecordWriter)写入到TFRecords文件。[`tensorflow/g3doc/how_tos/reading_data/convert_to_records.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/reading_data/convert_to_records.py)就是这样的一个例子。

从TFRecords文件中读取数据， 可以使用[`tf.TFRecordReader`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#TFRecordReader)的[`tf.parse_single_example`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#parse_single_example)解析器。这个`parse_single_example`操作可以将`Example`协议内存块(protocol buffer)解析为张量。 MNIST的例子就使用了`convert_to_records` 所构建的数据。 请参看[`tensorflow/g3doc/how_tos/reading_data/fully_connected_reader.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/reading_data/fully_connected_reader.py), 您也可以将这个例子跟`fully_connected_feed`的版本加以比较。

### 预处理 <a class="md-anchor" id="AUTOGENERATED-preprocessing"></a>

你可以对输入的样本进行任意的预处理， 这些预处理不依赖于训练参数， 你可以在[`tensorflow/models/image/cifar10/cifar10.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/cifar10.py)找到数据归一化， 提取随机数据片，增加噪声或失真等等预处理的例子。

### 批处理 <a class="md-anchor" id="AUTOGENERATED-batching"></a>

在数据输入管线的末端， 我们需要有另一个队列来执行输入样本的训练，评价和推理。因此我们使用[`tf.train.shuffle_batch` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#shuffle_batch)来对队列中的样本进行乱序处理

示例:

```
def read_my_file_format(filename_queue):
  reader = tf.SomeReader()
  key, record_string = reader.read(filename_queue)
  example, label = tf.some_decoder(record_string)
  processed_example = some_processing(example)
  return processed_example, label

def input_pipeline(filenames, batch_size, num_epochs=None):
  filename_queue = tf.train.string_input_producer(
      filenames, num_epochs=num_epochs, shuffle=True)
  example, label = read_my_file_format(filename_queue)
  # min_after_dequeue defines how big a buffer we will randomly sample
  #   from -- bigger means better shuffling but slower start up and more
  #   memory used.
  # capacity must be larger than min_after_dequeue and the amount larger
  #   determines the maximum we will prefetch.  Recommendation:
  #   min_after_dequeue + (num_threads + a small safety margin) * batch_size
  min_after_dequeue = 10000
  capacity = min_after_dequeue + 3 * batch_size
  example_batch, label_batch = tf.train.shuffle_batch(
      [example, label], batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch
```

如果你需要对不同文件中的样子有更强的乱序和并行处理，可以使用[`tf.train.shuffle_batch_join` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#shuffle_batch_join).
示例:

```
def read_my_file_format(filename_queue):
  # Same as above

def input_pipeline(filenames, batch_size, read_threads, num_epochs=None):
  filename_queue = tf.train.string_input_producer(
      filenames, num_epochs=num_epochs, shuffle=True)
  example_list = [read_my_file_format(filename_queue)
                  for _ in range(read_threads)]
  min_after_dequeue = 10000
  capacity = min_after_dequeue + 3 * batch_size
  example_batch, label_batch = tf.train.shuffle_batch_join(
      example_list, batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch
```

在这个例子中， 你虽然只使用了一个文件名队列， 但是TensorFlow依然能保证多个文件阅读器从同一次迭代(epoch)的不同文件中读取数据，知道这次迭代的所有文件都被开始读取为止。（通常来说一个线程来对文件名队列进行填充的效率是足够的）

另一种替代方案是： 使用[`tf.train.shuffle_batch` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#shuffle_batch),设置`num_threads`的值大于1。 这种方案可以保证同一时刻只在一个文件中进行读取操作(但是读取速度依然优于单线程)，而不是之前的同时读取多个文件。这种方案的优点是：
*   避免了两个不同的线程从同一个文件中读取同一个样本。
*   避免了过多的磁盘搜索操作。

你一共需要多少个读取线程呢？ 函数`tf.train.shuffle_batch*`为TensorFlow图提供了获取文件名队列中的元素个数之和的方法。 如果你有足够多的读取线程， 文件名队列中的元素个数之和应该一直是一个略高于0的数。具体可以参考[TensorBoard:可视化学习](tensorflow-zh/SOURCE/how_tos/summaries_and_tensorboard/index.md).

### Creating threads to prefetch using `QueueRunner` objects <a class="md-anchor" id="QueueRunner"></a>

The short version: many of the `tf.train` functions listed above add
[`QueueRunner`](tensorflow-zh/SOURCE/api_docs/python/train.md#QueueRunner) objects to your
graph.  These require that you call
[`tf.train.start_queue_runners`](tensorflow-zh/SOURCE/api_docs/python/train.md#start_queue_runners)
before running any training or inference steps, or it will hang forever. This
will start threads that run the input pipeline, filling the example queue so
that the dequeue to get the examples will succeed.  This is best combined with a
[`tf.train.Coordinator`](tensorflow-zh/SOURCE/api_docs/python/train.md#Coordinator) to cleanly
shut down these threads when there are errors. If you set a limit on the number
of epochs, that will use an epoch counter that will need to be intialized.  The
recommended code pattern combining these is:

```python
# Create the graph, etc.
init_op = tf.initialize_all_variables()

