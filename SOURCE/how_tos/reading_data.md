# 数据读取 <a class="md-anchor" id="AUTOGENERATED-reading-data"></a>

TensorFlow程序读取数据一共有3种方法:

*   供给数据(Feeding)： 在TensorFlow程序运行的每一步， 让Python代码来供给数据。
*   从文件读取数据： 在TensorFlow图的起始， 让一个输入管线从文件中读取数据。
*   预加载数据： 在TensorFlow图中定义常量或变量来保存所有数据(仅适用于数据量比较小的情况)。

<!-- TOC-BEGIN This section is generated by neural network: DO NOT EDIT! -->
## 目录
### [数据读取](#AUTOGENERATED-reading-data)
* [供给数据(Feeding)](#Feeding)
* [从文件读取数据](#AUTOGENERATED-reading-from-files)
  * [文件名, 乱序(shuffling), 和最大文件采样数(epoch limits)](#AUTOGENERATED-filenames--shuffling--and-epoch-limits)
  * [文件格式](#AUTOGENERATED-file-formats)
  * [预处理](#AUTOGENERATED-preprocessing)
  * [批处理](#AUTOGENERATED-batching)
  * [使用`QueueRunner`创建预读线程](#QueueRunner)
  * [对记录进行过滤或者为每个纪录创建多个样本](#AUTOGENERATED-filtering-records-or-producing-multiple-examples-per-record)
  * [序列化输入数据(Sparse input data)](#AUTOGENERATED-sparse-input-data)
* [预加载数据](#AUTOGENERATED-preloaded-data)
* [多管线输入](#AUTOGENERATED-multiple-input-pipelines)


<!-- TOC-END This section was generated by neural network, THANKS FOR READING! -->

## 供给数据 <a class="md-anchor" id="Feeding"></a>

TensorFlow的数据供给机制允许你在TensorFlow运算图中将数据注入到任一张量中。因此，python运算可以把数据直接设置到TensorFlow图中。

通过给run()或者eval()函数输入`feed_dict`参数， 可以启动运算过程。

```python
with tf.Session():
  input = tf.placeholder(tf.float32)
  classifier = ...
  print classifier.eval(feed_dict={input: my_python_preprocessing_fn()})
```

虽然你可以使用常量和变量来替换任何一个张量， 但是最好的做法应该是使用[`placeholder` op](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#placeholder)节点。设计`placeholder`节点的唯一的意图就是为了提供数据供给(feeding)的方法。`placeholder`节点被声明的时候是未初始化的， 也不包含数据， 如果没有为它供给数据， 则TensorFlow运算的时候会产生错误， 所以千万不要忘了为`placeholder`提供数据。

可以在[`tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/tutorials/mnist/fully_connected_feed.py)找到使用`placeholder`和MNIST训练的例子，[MNIST tutorial](tensorflow-zh/SOURCE/tutorials/mnist/tf/index.md)也讲述了这一例子。

## 从文件读取数据 <a class="md-anchor" id="AUTOGENERATED-reading-from-files"></a>

一共典型的文件读取管线会包含下面这些步骤：

1.  文件名列表
2.  *可配置的* 文件名乱序(shuffling)
3.  *可配置的* 采样的最大文件个数(epoch limit)
4.  文件名队列
5.  针对输入文件格式的阅读器
6.  纪录解析器
7.  *可配置的*预处理器
8.  样本队列

### 文件名, 乱序(shuffling), 和最大训练迭代数(epoch limits) <a class="md-anchor" id="AUTOGENERATED-filenames--shuffling--and-epoch-limits"></a>

可以使用字符串张量(比如`["file0", "file1"]`, `[("file%d" % i) for i in range(2)]`， `[("file%d" % i) for i in range(2)]`) 或者[`tf.train.match_filenames_once` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#match_filenames_once)来产生文件名列表。

将文件名列表交给[`tf.train.string_input_producer` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#string_input_producer).`string_input_producer`来生成一个先入先出的队列， 文件阅读器会需要它来读取数据。

`string_input_producer` 提供的可配置参数来设置文件名乱序和最大的训练迭代数， `QueueRunner`会为每次迭代(epoch)将所有的文件名加入文件名队列中， 如果`shuffle=True`的话， 会对文件名进行乱序处理。这一过程是比较均匀的，因此它可以产生均衡的文件名队列。

这个`QueueRunner`的工作线程是独立于文件阅读器的线程， 因此乱序和将文件名推入到文件名队列这些过程不会阻塞文件阅读器运行。

### 文件格式 <a class="md-anchor" id="AUTOGENERATED-file-formats"></a>

根据你的文件格式， 选择对应的文件阅读器， 然后将文件名队列提供给阅读器的`read`方法。阅读器的`read`方法会输出一个key来表征输入的文件和其中的纪录(对于调试非常有用)，同时得到一个字符串标量， 这个字符串标量可以被一个或多个解析器，或者转换操作将其解码为张量并且构造称为样本。

#### CSV 文件 <a class="md-anchor" id="AUTOGENERATED-csv-files"></a>

从CSV文件中读取数据， 需要使用[`TextLineReader`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#TextLineReader)和[`decode_csv`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#decode_csv) 操作， 如下面的例子所示：

```python
filename_queue = tf.train.string_input_producer(["file0.csv", "file1.csv"])

reader = tf.TextLineReader()
key, value = reader.read(filename_queue)

# Default values, in case of empty columns. Also specifies the type of the
# decoded result.
record_defaults = [[1], [1], [1], [1], [1]]
col1, col2, col3, col4, col5 = tf.decode_csv(
    value, record_defaults=record_defaults)
features = tf.concat(0, [col1, col2, col3, col4])

with tf.Session() as sess:
  # Start populating the filename queue.
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)

  for i in range(1200):
    # Retrieve a single instance:
    example, label = sess.run([features, col5])

  coord.request_stop()
  coord.join(threads)
```
每次`read`的执行都会从文件中读取一行内容， `decode_csv` 操作会解析这一行内容并将其转为张量列表。如果输入的参数有缺失，`record_default`参数可以根据张量的类型来设置默认值。

在调用`run`或者`eval`去执行`read`之前， 你必须调用`tf.train.start_queue_runners`来将文件名填充到队列。否则`read`操作会被阻塞到文件名队列中有值为止。

#### Fixed length records <a class="md-anchor" id="AUTOGENERATED-fixed-length-records"></a>

To read binary files in which each record is a fixed number of bytes, use
[`tf.FixedLengthRecordReader`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#FixedLengthRecordReader)
with the [`tf.decode_raw`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#decode_raw) operation.
The `decode_raw` op converts from a string to a uint8 tensor.

For example, [the CIFAR-10 dataset](http://www.cs.toronto.edu/~kriz/cifar.html)
uses a file format where each record is represented using a fixed number of
bytes: 1 byte for the label followed by 3072 bytes of image data. Once you have
a uint8 tensor, standard operations can slice out each piece and reformat as
needed. For CIFAR-10, you can see how to do the reading and decoding in
[`tensorflow/models/image/cifar10/cifar10_input.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/cifar10_input.py)
and described in
[this tutorial](tensorflow-zh/SOURCE/tutorials/deep_cnn/index.md#prepare-the-data).

#### Standard TensorFlow format <a class="md-anchor" id="AUTOGENERATED-standard-tensorflow-format"></a>

Another approach is to convert whatever data you have into a supported format.
This approach makes it easier to mix and match data sets and network
architectures. The recommended format for TensorFlow is a TFRecords file
containing
[`tf.train.Example` protocol buffers](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/example.proto)
(which contain
[`Features`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/core/example/feature.proto)
as a field).  You write a little program that gets your data, stuffs it in an
`Example` protocol buffer, serializes the protocol buffer to a string, and then
writes the string to a TFRecords file using the
[`tf.python_io.TFRecordWriter` class](tensorflow-zh/SOURCE/api_docs/python/python_io.md#TFRecordWriter).
For example,
[`tensorflow/g3doc/how_tos/reading_data/convert_to_records.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/reading_data/convert_to_records.py)
converts MNIST data to this format.

To read a file of TFRecords, use
[`tf.TFRecordReader`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#TFRecordReader) with
the [`tf.parse_single_example`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#parse_single_example)
decoder. The `parse_single_example` op decodes the example protocol buffers into
tensors. An MNIST example using the data produced by `convert_to_records` can be
found in
[`tensorflow/g3doc/how_tos/reading_data/fully_connected_reader.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/reading_data/fully_connected_reader.py),
which you can compare with the `fully_connected_feed` version.

### 预处理 <a class="md-anchor" id="AUTOGENERATED-preprocessing"></a>

你可以对输入的样本进行任意的预处理， 这些预处理不依赖于训练参数， 你可以在[`tensorflow/models/image/cifar10/cifar10.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/models/image/cifar10/cifar10.py)找到数据归一化， 提取随机数据片，增加噪声或失真等等预处理的例子。

### 批处理 <a class="md-anchor" id="AUTOGENERATED-batching"></a>

在数据输入管线的末端， 我们需要有另一个队列来执行输入样本的训练，评价和推理。因此我们使用[`tf.train.shuffle_batch` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#shuffle_batch)来对队列中的样本进行乱序处理

示例:

```
def read_my_file_format(filename_queue):
  reader = tf.SomeReader()
  key, record_string = reader.read(filename_queue)
  example, label = tf.some_decoder(record_string)
  processed_example = some_processing(example)
  return processed_example, label

def input_pipeline(filenames, batch_size, num_epochs=None):
  filename_queue = tf.train.string_input_producer(
      filenames, num_epochs=num_epochs, shuffle=True)
  example, label = read_my_file_format(filename_queue)
  # min_after_dequeue defines how big a buffer we will randomly sample
  #   from -- bigger means better shuffling but slower start up and more
  #   memory used.
  # capacity must be larger than min_after_dequeue and the amount larger
  #   determines the maximum we will prefetch.  Recommendation:
  #   min_after_dequeue + (num_threads + a small safety margin) * batch_size
  min_after_dequeue = 10000
  capacity = min_after_dequeue + 3 * batch_size
  example_batch, label_batch = tf.train.shuffle_batch(
      [example, label], batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch
```

如果你需要对不同文件中的样子有更强的乱序和并行处理，可以使用[`tf.train.shuffle_batch_join` 函数](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#shuffle_batch_join).
示例:

```
def read_my_file_format(filename_queue):
  # Same as above

def input_pipeline(filenames, batch_size, read_threads, num_epochs=None):
  filename_queue = tf.train.string_input_producer(
      filenames, num_epochs=num_epochs, shuffle=True)
  example_list = [read_my_file_format(filename_queue)
                  for _ in range(read_threads)]
  min_after_dequeue = 10000
  capacity = min_after_dequeue + 3 * batch_size
  example_batch, label_batch = tf.train.shuffle_batch_join(
      example_list, batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch
```

在这个例子中， 你虽然只使用了一个文件名队列， 但是TensorFlow依然能保证多个文件阅读器从同一次迭代(epoch)的不同文件中读取数据，知道这次迭代的所有文件都被开始读取为止。（通常来说一个线程来对文件名队列进行填充的效率是足够的）

另一种替代方案是： 使用[`tf.train.shuffle_batch` function](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#shuffle_batch),设置`num_threads`的值大于1。 这种方案可以保证同一时刻只在一个文件中进行读取操作(但是读取速度依然优于单线程)，而不是之前的同时读取多个文件。这种方案的优点是：
*   避免了两个不同的线程从同一个文件中读取同一个样本。
*   避免了过多的磁盘搜索操作。

你一共需要多少个读取线程呢？ 函数`tf.train.shuffle_batch*`为TensorFlow图提供了获取文件名队列中的元素个数之和的方法。 如果你有足够多的读取线程， 文件名队列中的元素个数之和应该一直是一个略高于0的数。你可以参考[TensorBoard:可视化学习](tensorflow-zh/SOURCE/how_tos/summaries_and_tensorboard/index.md).

### Creating threads to prefetch using `QueueRunner` objects <a class="md-anchor" id="QueueRunner"></a>

The short version: many of the `tf.train` functions listed above add
[`QueueRunner`](tensorflow-zh/SOURCE/api_docs/python/train.md#QueueRunner) objects to your
graph.  These require that you call
[`tf.train.start_queue_runners`](tensorflow-zh/SOURCE/api_docs/python/train.md#start_queue_runners)
before running any training or inference steps, or it will hang forever. This
will start threads that run the input pipeline, filling the example queue so
that the dequeue to get the examples will succeed.  This is best combined with a
[`tf.train.Coordinator`](tensorflow-zh/SOURCE/api_docs/python/train.md#Coordinator) to cleanly
shut down these threads when there are errors. If you set a limit on the number
of epochs, that will use an epoch counter that will need to be intialized.  The
recommended code pattern combining these is:

```python
# Create the graph, etc.
init_op = tf.initialize_all_variables()

# Create a session for running operations in the Graph.
sess = tf.Session()

# Initialize the variables (like the epoch counter).
sess.run(init_op)

# Start input enqueue threads.
coord = tf.train.Coordinator()
threads = tf.train.start_queue_runners(sess=sess, coord=coord)

try:
    while not coord.should_stop():
        # Run training steps or whatever
        sess.run(train_op)

except tf.errors.OutOfRangeError:
    print 'Done training -- epoch limit reached'
finally:
    # When done, ask the threads to stop.
    coord.request_stop()

# Wait for threads to finish.
coord.join(threads)
sess.close()
```

#### Aside: What is happening here? <a class="md-anchor" id="AUTOGENERATED-aside--what-is-happening-here-"></a>

First we create the graph. It will have a few pipeline stages that are
connected by queues. The first stage will generate filenames to read and enqueue
them in the filename queue. The second stage consumes filenames (using a
`Reader`), produces examples, and enqueues them in an example queue. Depending
on how you have set things up, you may actually have a few independent copies of
the second stage, so that you can read from multiple files in parallel. At the
end of these stages is an enqueue operation, which enqueues into a queue that
the next stage dequeues from. We want to start threads running these enqueuing
operations, so that our training loop can dequeue examples from the example
queue.

<div style="width:70%; margin-left:12%; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="AnimatedFileQueues.gif">
</div>

The helpers in `tf.train` that create these queues and enqueuing operations add
a [`tf.train.QueueRunner`](tensorflow-zh/SOURCE/api_docs/python/train.md#QueueRunner) to the
graph using the
[`tf.train.add_queue_runner`](tensorflow-zh/SOURCE/api_docs/python/train.md#add_queue_runner)
function. Each `QueueRunner` is responsible for one stage, and holds the list of
enqueue operations that need to be run in threads. Once the graph is
constructed, the
[`tf.train.start_queue_runners`](tensorflow-zh/SOURCE/api_docs/python/train.md#start_queue_runners)
function asks each QueueRunner in the graph to start its threads running the
enqueuing operations.

If all goes well, you can now run your training steps and the queues will be
filled by the background threads. If you have set an epoch limit, at some point
an attempt to dequeue examples will get an
[`tf.OutOfRangeError`](tensorflow-zh/SOURCE/api_docs/python/client.md#OutOfRangeError).  This
is the TensorFlow equivalent of "end of file" (EOF) -- this means the epoch
limit has been reached and no more examples are available.

The last ingredient is the
[`Coordinator`](tensorflow-zh/SOURCE/api_docs/python/train.md#Coordinator). This is responsible
for letting all the threads know if anything has signalled a shut down. Most
commonly this would be because an exception was raised, for example one of the
threads got an error when running some operation (or an ordinary Python
exception).

For more about threading, queues, QueueRunners, and Coordinators
[see here](tensorflow-zh/SOURCE/how_tos/threading_and_queues/index.md).

#### Aside: How clean shut-down when limiting epochs works <a class="md-anchor" id="AUTOGENERATED-aside--how-clean-shut-down-when-limiting-epochs-works"></a>

Imagine you have a model that has set a limit on the number of epochs to train
on.  That means that the thread generating filenames will only run that many
times before generating an `OutOfRange` error. The QueueRunner will catch that
error, close the filename queue, and exit the thread. Closing the queue does two
things:

*   Any future attempt to enqueue in the filename queue will generate an error.
    At this point there shouldn't be any threads trying to do that, but this
    is helpful when queues are closed due to other errors.
*   Any current or future dequeue will either succeed (if there are enough
    elements left) or fail (with an `OutOfRange` error) immediately.  They won't
    block waiting for more elements to be enqueued, since by the previous point
    that can't happen.

The point is that when the filename queue is closed, there will likely still be
many filenames in that queue, so the next stage of the pipeline (with the reader
and other preprocessing) may continue running for some time.  Once the filename
queue is exhausted, though, the next attempt to dequeue a filename (e.g. from a
reader that has finished with the file it was working on) will trigger an
`OutOfRange` error.  In this case, though, you might have multiple threads
associated with a single QueueRunner.  If this isn't the last thread in the
QueueRunner, the `OutOfRange` error just causes the one thread to exit.  This
allows the other threads, which are still finishing up their last file, to
proceed until they finish as well.  (Assuming you are using a
[`tf.train.Coordinator`](tensorflow-zh/SOURCE/api_docs/python/train.md#Coordinator),
other types of errors will cause all the threads to stop.)  Once all the reader
threads hit the `OutOfRange` error, only then does the next queue, the example
queue, gets closed.

Again, the example queue will have some elements queued, so training will
continue until those are exhausted.  If the example queue is a
[`RandomShuffleQueue`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#RandomShuffleQueue), say
because you are using `shuffle_batch` or `shuffle_batch_join`, it normally will
avoid ever going having fewer than its `min_after_dequeue` attr elements
buffered.  However, once the queue is closed that restriction will be lifted and
the queue will eventually empty.  At that point the actual training threads,
when they try and dequeue from example queue, will start getting `OutOfRange`
errors and exiting.  Once all the training threads are done,
[`tf.train.Coordinator.join`](tensorflow-zh/SOURCE/api_docs/python/train.md#Coordinator.join)
will return and you can exit cleanly.

### Filtering records or producing multiple examples per record <a class="md-anchor" id="AUTOGENERATED-filtering-records-or-producing-multiple-examples-per-record"></a>

Instead of examples with shapes `[x, y, z]`, you will produce a batch of
examples with shape `[batch, x, y, z]`.  The batch size can be 0 if you want to
filter this record out (maybe it is in a hold-out set?), or bigger than 1 if you
are producing multiple examples per record.  Then simply set `enqueue_many=True`
when calling one of the batching functions (such as `shuffle_batch` or
`shuffle_batch_join`).

### Sparse input data <a class="md-anchor" id="AUTOGENERATED-sparse-input-data"></a>

SparseTensors don't play well with queues. If you use SparseTensors you have
to decode the string records using
[`tf.parse_example`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#parse_example) **after**
batching (instead of using `tf.parse_single_example` before batching).

## Preloaded data <a class="md-anchor" id="AUTOGENERATED-preloaded-data"></a>

This is only used for small data sets that can be loaded entirely in memory.
There are two approaches:

* Store the data in a constant.
* Store the data in a variable, that you initialize and then never change.

Using a constant is a bit simpler, but uses more memory (since the constant is
stored inline in the graph data structure, which may be duplicated a few times).

```python
training_data = ...
training_labels = ...
with tf.Session():
  input_data = tf.constant(training_data)
  input_labels = tf.constant(training_labels)
  ...
```

To instead use a variable, you need to also initialize it after the graph has been built.

```python
training_data = ...
training_labels = ...
with tf.Session() as sess:
  data_initializer = tf.placeholder(dtype=training_data.dtype,
                                    shape=training_data.shape)
  label_initializer = tf.placeholder(dtype=training_labels.dtype,
                                     shape=training_labels.shape)
  input_data = tf.Variable(data_initalizer, trainable=False, collections=[])
  input_labels = tf.Variable(label_initalizer, trainable=False, collections=[])
  ...
  sess.run(input_data.initializer,
           feed_dict={data_initializer: training_data})
  sess.run(input_labels.initializer,
           feed_dict={label_initializer: training_lables})
```

Setting `trainable=False` keeps the variable out of the
`GraphKeys.TRAINABLE_VARIABLES` collection in the graph, so we won't try and
update it when training.  Setting `collections=[]` keeps the variable out of the
`GraphKeys.VARIABLES` collection used for saving and restoring checkpoints.

Either way,
[`tf.train.slice_input_producer function`](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#slice_input_producer)
can be used to produce a slice at a time.  This shuffles the examples across an
entire epoch, so further shuffling when batching is undesirable.  So instead of
using the `shuffle_batch` functions, we use the plain
[`tf.train.batch` function](tensorflow-zh/SOURCE/api_docs/python/io_ops.md#batch).  To use
multiple preprocessing threads, set the `num_threads` parameter to a number
bigger than 1.

An MNIST example that preloads the data using constants can be found in
[`tensorflow/g3doc/how_tos/reading_data/fully_connected_preloaded.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/reading_data/fully_connected_preloaded.py), and one that preloads the data using variables can be found in
[`tensorflow/g3doc/how_tos/reading_data/fully_connected_preloaded_var.py`](https://tensorflow.googlesource.com/tensorflow/+/master/tensorflow/g3doc/how_tos/reading_data/fully_connected_preloaded_var.py),
You can compare these with the `fully_connected_feed` and
`fully_connected_reader` versions above.

## Multiple input pipelines <a class="md-anchor" id="AUTOGENERATED-multiple-input-pipelines"></a>

Commonly you will want to train on one dataset and evaluate (or "eval") on
another.  One way to do this is to actually have two separate processes:

* The training process reads training input data and periodically writes
  checkpoint files with all the trained variables.
* The evaluation process restores the checkpoint files into an inference
  model that reads validation input data.

This is what is done in
[the example CIFAR-10 model](tensorflow-zh/SOURCE/tutorials/deep_cnn/index.md#save-and-restore-checkpoints).  This has a couple of benefits:

* The eval is performed on a single snapshot of the trained variables.
* You can perform the eval even after training has completed and exited.

You can have the train and eval in the same graph in the same process, and share
their trained variables.  See
[the shared variables tutorial](tensorflow-zh/SOURCE/how_tos/variable_scope/index.md).
