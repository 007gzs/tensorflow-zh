# 下载与安装 <a class="md-anchor" id="AUTOGENERATED-download-and-setup"></a>

You can install TensorFlow using our provided binary packages or from source.
你可以使用我们提供的二进制包, 或者通过软件源, 安装 TensorFlow.

## 二进制安装 <a class="md-anchor" id="AUTOGENERATED-binary-installation"></a>

The TensorFlow Python API requires Python 2.7.
TensorFlow Python API 依赖 Python 2.7 版本.

The simplest way to install TensorFlow is using
[pip](https://pypi.python.org/pypi/pip) for both Linux and Mac.
在 Linux 和 Mac 下最简单的安装方式, 是使用 [pip](https://pypi.python.org/pypi/pip)
进行安装.

If you encounter installation errors, see
[common problems](#common_install_problems) for some solutions. To simplify
installation, please consider using our virtualenv-based instructions
[here](#virtualenv_install).
如果在安装过程中遇到错误, 请查阅 [常见问题](#common_install_problems).
为了简化安装, 建议使用 virtualenv, 相关说明参见[这里](#virtualenv_install).

### Ubuntu/Linux <a class="md-anchor" id="AUTOGENERATED-ubuntu-linux"></a>

```bash
# 仅使用 CPU 的版本
$ pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl

# 开启 GPU 支持的版本 (安装该版本的前提是已经安装了 CUDA sdk)
$ pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
```

### Mac OS X <a class="md-anchor" id="AUTOGENERATED-mac-os-x"></a>

On OS X, we recommend installing [homebrew](http://brew.sh) and `brew install
python` before proceeding, or installing TensorFlow within [virtualenv](#virtualenv_install).
在 OS X 系统上, 我们推荐使用通过 [homebrew](http://brew.sh) 安装的 Python (`brew install python`), 并将在 virtualenv 虚拟环境中安装 TensorFlow.

```bash
# 当前版本只支持 CPU
$ pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl
```

## 基于 Docker 的安装 <a class="md-anchor" id="AUTOGENERATED-docker-based-installation"></a>

We also support running TensorFlow via [Docker](http://docker.com/), which lets
you avoid worrying about setting up dependencies.
我们也支持通过 [Docker](http://docker.com/) 运行 TensorFlow. 该方式的优点是不用
操心软件依赖问题.

First, [install Docker](http://docs.docker.com/engine/installation/). Once
Docker is up and running, you can start a container with one command:
首先, [安装 Docker](http://docs.docker.com/engine/installation/). 一旦 Docker
已经启动运行, 可以通过命令启动一个容器:

```bash
$ docker run -it b.gcr.io/tensorflow/tensorflow
```

This will start a container with TensorFlow and all its dependencies already
installed.
该命令将启动一个安装好 TensorFlow 及相关依赖的容器.

### 其它镜像 <a class="md-anchor" id="AUTOGENERATED-additional-images"></a>

The default Docker image above contains just a minimal set of libraries for
getting up and running with TensorFlow. We also have the following container,
which you can use in the `docker run` command above:
默认的 Docker 镜像只包含启动和运行 TensorFlow 所需依赖库的一个最小集. 我们还提供了
下面一个镜像, 同样可以通过上述 `docker run` 命令安装:

* `b.gcr.io/tensorflow/tensorflow-full`: Contains a complete TensorFlow source
  installation, including all utilities needed to build and run TensorFlow. This
  makes it easy to experiment directly with the source, without needing to
  install any of the dependencies described above.
* `b.gcr.io/tensorflow/tensorflow-full`: 镜像中的 TensorFlow 是从源代码完整安装的,
  包含了编译和运行 TensorFlow 所需的全部工具. 使用该镜像, 不需要再安装任何的依赖,
  就可以直接使用源代码进行实验.

## 基于 VirtualEnv 的安装 <a class="md-anchor" id="virtualenv_install"></a>

We recommend using [virtualenv](https://pypi.python.org/pypi/virtualenv) to
create an isolated container and install TensorFlow in that container -- it is
optional but makes verifying installation issues easier.
我们推荐使用 [virtualenv](https://pypi.python.org/pypi/virtualenv) 创建一个隔离
的容器, 来安装 TensorFlow. 这不是强制的, 但是可以使得排查安装问题变得更容易.

First, install all required tools:
首先, 安装所有必须的工具:

```bash
# On Linux:
# 在 Linux 上:
$ sudo apt-get install python-pip python-dev python-virtualenv

# On Mac:
# 在 Mac 上:
$ sudo easy_install pip  # 确保 pip 已经安装
$ sudo pip install --upgrade virtualenv
```

Next, set up a new virtualenv environment.  To set it up in the
directory `~/tensorflow`, run:
接下来, 建立一个全新的 virtualenv 环境. 假设将环境建在 `~/tensorflow`
目录下, 执行:

```bash
$ virtualenv --system-site-packages ~/tensorflow
$ cd ~/tensorflow
```

Then activate the virtualenv:
然后, 激活 virtualenv:

```bash
$ source bin/activate  # 如果使用 bash
$ source bin/activate.csh  # 如果使用 csh
(tensorflow)$  # 终端提示符应该发生变化
```

Inside the virtualenv, install TensorFlow:
在 virtualenv 内, 安装 TensorFlow:

```bash
(tensorflow)$ pip install --upgrade <$url_to_binary.whl>
```

You can then run your TensorFlow program like:
接下来, 使用类似命令运行 TensorFlow 程序:

```bash
(tensorflow)$ cd tensorflow/models/image/mnist
(tensorflow)$ python convolutional.py

# When you are done using TensorFlow:
# 当使用完 TensorFlow
(tensorflow)$ deactivate  # 停用 virtualenv

$  # 你的命令提示符会恢复原样
```

## 尝试你的第一个 TensorFlow 程序 <a class="md-anchor" id="AUTOGENERATED-try-your-first-tensorflow-program"></a>

### (可选) 启用 GPU 支持 <a class="md-anchor" id="AUTOGENERATED--optional--enable-gpu-support"></a>

If you installed the GPU-enabled TensorFlow pip binary, you must have the
correct versions of the CUDA SDK and CUDNN installed on your
system.  Please see [the CUDA installation instructions](#install_cuda).
如果你使用的 TensorFlow 是通过 pip 安装的, 且开启了 GPU 支持, 你必须确保
系统里安装了正确的 CUDA sdk 和 CUDNN. 请参间  [CUDA 安装指南](#install_cuda:st 

You also need to set the `LD_LIBRARY_PATH` and `CUDA_HOME` environment
variables.  Consider adding the commands below to your `~/.bash_profile`.  These
assume your CUDA installation is in `/usr/local/cuda`:
你还需要设置 `LD_LIBRARY_PATH` 和 `CUDA_HOME` 环境变量. 可以考虑将下面的命令
添加到 `~/.bash_profile` 文件中, 这样每次登陆后自动生效. 注意, 下面的命令
假定 CUDA 安装目录为 `/usr/local/cuda`.

```bash
export LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/cuda/lib64"
export CUDA_HOME=/usr/local/cuda
```

### Run TensorFlow <a class="md-anchor" id="AUTOGENERATED-run-tensorflow"></a>

Open a python terminal:

```bash
$ python

>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> print sess.run(hello)
Hello, TensorFlow!
>>> a = tf.constant(10)
>>> b = tf.constant(32)
>>> print sess.run(a+b)
42
>>>

```

## Installing from sources <a class="md-anchor" id="source"></a>

### Clone the TensorFlow repository <a class="md-anchor" id="AUTOGENERATED-clone-the-tensorflow-repository"></a>

```bash
$ git clone --recurse-submodules https://github.com/tensorflow/tensorflow
```

`--recurse-submodules` is required to fetch the protobuf library that TensorFlow
depends on.

### Installation for Linux <a class="md-anchor" id="AUTOGENERATED-installation-for-linux"></a>

#### Install Bazel <a class="md-anchor" id="AUTOGENERATED-install-bazel"></a>


Follow instructions [here](http://bazel.io/docs/install.html) to install the
dependencies for Bazel. Then download and build the Bazel source with the
following commands:

```bash
$ git clone https://github.com/bazelbuild/bazel.git
$ cd bazel
$ git checkout tags/0.1.0
$ ./compile.sh
```

These commands use the commit tag `0.1.0`, which is known to work with
TensorFlow. `HEAD` may be unstable.

Add the executable `output/bazel` to your `$PATH` environment variable.

#### Install other dependencies <a class="md-anchor" id="AUTOGENERATED-install-other-dependencies"></a>

```bash
$ sudo apt-get install python-numpy swig python-dev
```

#### Optional: Install CUDA (GPUs on Linux) <a class="md-anchor" id="install_cuda"></a>

In order to build or run TensorFlow with GPU support, both Cuda Toolkit 7.0 and
CUDNN 6.5 V2 from NVIDIA need to be installed.

TensorFlow GPU support requires having a GPU card with NVidia Compute Capability >= 3.5.  Supported cards include but are not limited to:

* NVidia Titan
* NVidia Titan X
* NVidia K20
* NVidia K40

##### Download and install Cuda Toolkit 7.0 <a class="md-anchor" id="AUTOGENERATED-download-and-install-cuda-toolkit-7.0"></a>

https://developer.nvidia.com/cuda-toolkit-70

Install the toolkit into e.g. `/usr/local/cuda`

##### Download and install CUDNN Toolkit 6.5 <a class="md-anchor" id="AUTOGENERATED-download-and-install-cudnn-toolkit-6.5"></a>

https://developer.nvidia.com/rdp/cudnn-archive

Uncompress and copy the cudnn files into the toolkit directory.  Assuming the
toolkit is installed in `/usr/local/cuda`:

``` bash
tar xvzf cudnn-6.5-linux-x64-v2.tgz
sudo cp cudnn-6.5-linux-x64-v2/cudnn.h /usr/local/cuda/include
sudo cp cudnn-6.5-linux-x64-v2/libcudnn* /usr/local/cuda/lib64
```

##### Configure TensorFlow's canonical view of Cuda libraries <a class="md-anchor" id="AUTOGENERATED-configure-tensorflow-s-canonical-view-of-cuda-libraries"></a>
From the root of your source tree, run:

``` bash
$ ./configure
Do you wish to bulid TensorFlow with GPU support? [y/n] y
GPU support will be enabled for TensorFlow

Please specify the location where CUDA 7.0 toolkit is installed. Refer to
README.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda

Please specify the location where CUDNN 6.5 V2 library is installed. Refer to
README.md for more details. [default is: /usr/local/cuda]: /usr/local/cuda

Setting up Cuda include
Setting up Cuda lib64
Setting up Cuda bin
Setting up Cuda nvvm
Configuration finished
```

This creates a canonical set of symbolic links to the Cuda libraries on your system.
Every time you change the Cuda library paths you need to run this step again before
you invoke the bazel build command.

##### Build your target with GPU support. <a class="md-anchor" id="AUTOGENERATED-build-your-target-with-gpu-support."></a>
From the root of your source tree, run:

```bash
$ bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
# Lots of output. This tutorial iteratively calculates the major eigenvalue of
# a 2x2 matrix, on GPU. The last few lines look like this.
000009/000005 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]
000006/000001 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]
000009/000009 lambda = 2.000000 x = [0.894427 -0.447214] y = [1.788854 -0.894427]
```

Note that "--config=cuda" is needed to enable the GPU support.

##### Known issues <a class="md-anchor" id="AUTOGENERATED-known-issues"></a>

* Although it is possible to build both Cuda and non-Cuda configs under the same
source tree, we recommend to run "bazel clean" when switching between these two
configs in the same source tree.

* You have to run configure before running bazel build. Otherwise, the build
will fail with a clear error message. In the future, we might consider making
this more conveninent by including the configure step in our build process,
given necessary bazel new feature support.

### Installation for Mac OS X <a class="md-anchor" id="AUTOGENERATED-installation-for-mac-os-x"></a>

Mac needs the same set of dependencies as Linux, however their installing those
dependencies is different. Here is a set of useful links to help with installing
the dependencies on Mac OS X :

#### Bazel <a class="md-anchor" id="AUTOGENERATED-bazel"></a>

Look for installation instructions for Mac OS X on
[this](http://bazel.io/docs/install.html) page.

#### SWIG <a class="md-anchor" id="AUTOGENERATED-swig"></a>

[Mac OS X installation](http://www.swig.org/Doc3.0/Preface.html#Preface_osx_installation).

Notes : You need to install
[PCRE](ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/) and *NOT* PCRE2.

#### Numpy <a class="md-anchor" id="AUTOGENERATED-numpy"></a>

Follow installation instructions [here](http://docs.scipy.org/doc/numpy/user/install.html).


### Create the pip package and install <a class="md-anchor" id="create-pip"></a>

```bash
$ bazel build -c opt //tensorflow/tools/pip_package:build_pip_package

$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

# The name of the .whl file will depend on your platform.
$ pip install /tmp/tensorflow_pkg/tensorflow-0.5.0-cp27-none-linux_x86_64.whl
```

## Train your first TensorFlow neural net model <a class="md-anchor" id="AUTOGENERATED-train-your-first-tensorflow-neural-net-model"></a>

Starting from the root of your source tree, run:

```python
$ cd tensorflow/models/image/mnist
$ python convolutional.py
Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.
Succesfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.
Succesfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.
Succesfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.
Extracting data/train-images-idx3-ubyte.gz
Extracting data/train-labels-idx1-ubyte.gz
Extracting data/t10k-images-idx3-ubyte.gz
Extracting data/t10k-labels-idx1-ubyte.gz
Initialized!
Epoch 0.00
Minibatch loss: 12.054, learning rate: 0.010000
Minibatch error: 90.6%
Validation error: 84.6%
Epoch 0.12
Minibatch loss: 3.285, learning rate: 0.010000
Minibatch error: 6.2%
Validation error: 7.0%
...
...
```

## Common Problems <a class="md-anchor" id="common_install_problems"></a>

### GPU-related issues <a class="md-anchor" id="AUTOGENERATED-gpu-related-issues"></a>

If you encounter the following when trying to run a TensorFlow program:

```python
ImportError: libcudart.so.7.0: cannot open shared object file: No such file or directory
```

Make sure you followed the the GPU installation [instructions](#install_cuda).

### On Linux <a class="md-anchor" id="AUTOGENERATED-on-linux"></a>

If you encounter:

```python
...
 "__add__", "__radd__",
             ^
SyntaxError: invalid syntax
```

Solution: make sure you are using Python 2.7.

### On MacOSX <a class="md-anchor" id="AUTOGENERATED-on-macosx"></a>


If you encounter:

```python
import six.moves.copyreg as copyreg

ImportError: No module named copyreg
```

Solution: TensorFlow depends on protobuf, which requires `six-1.10.0`. Apple's
default python environment has `six-1.4.1` and may be difficult to upgrade.
There are several ways to fix this:

1. Upgrade the system-wide copy of `six`:

    ```bash
    sudo easy_install -U six
    ```

2. Install a separate copy of python via homebrew:

    ```bash
    brew install python
    ```

3. Build or use TensorFlow
   [within `virtualenv`](#virtualenv_install).



If you encounter:

```
>>> import tensorflow as tf
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py", line 4, in <module>
    from tensorflow.python import *
  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py", line 13, in <module>
    from tensorflow.core.framework.graph_pb2 import *
...
  File "/usr/local/lib/python2.7/site-packages/tensorflow/core/framework/tensor_shape_pb2.py", line 22, in <module>
    serialized_pb=_b('\n,tensorflow/core/framework/tensor_shape.proto\x12\ntensorflow\"d\n\x10TensorShapeProto\x12-\n\x03\x64im\x18\x02 \x03(\x0b\x32 .tensorflow.TensorShapeProto.Dim\x1a!\n\x03\x44im\x12\x0c\n\x04size\x18\x01 \x01(\x03\x12\x0c\n\x04name\x18\x02 \x01(\tb\x06proto3')
TypeError: __init__() got an unexpected keyword argument 'syntax'
```

This is due to a conflict between protobuf versions (we require protobuf 3.0.0).
The best current solution is to make sure older versions of protobuf are not
installed, such as:

```bash
brew reinstall --devel protobuf
```
为了简化安装, 请考虑使用 virtualenv, 相关说明参见[这里](#virtualenv_install).
